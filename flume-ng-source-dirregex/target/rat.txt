
*****************************************************
Summary
-------
Notes: 0
Binaries: 0
Archives: 0
Standards: 8

Apache Licensed: 4
Generated Documents: 0

JavaDocs are generated and so license header is optional
Generated files do not required license headers

4 Unknown Licenses

*******************************

Unapproved licenses:

  src/main/java/com/changhong/bigdata/flume/source/dirnginx/NginxSource.java
  src/main/java/com/jackniu/SpoolSource.java
  src/main/java/com/jackniu/Test.java
  src/main/java/com/jackniu/TestEventSource.java

*******************************

Archives:

*****************************************************
  Files with Apache License headers will be marked AL
  Binary files (which do not require AL headers) will be marked B
  Compressed archives will be marked A
  Notices, licenses etc will be marked N
  AL    pom.xml
 !????? src/main/java/com/changhong/bigdata/flume/source/dirnginx/NginxSource.java
  AL    src/main/java/com/changhong/bigdata/flume/source/dirregex/DirRegexSource.java
 !????? src/main/java/com/jackniu/SpoolSource.java
 !????? src/main/java/com/jackniu/Test.java
 !????? src/main/java/com/jackniu/TestEventSource.java
  AL    src/test/java/com/changhong/bigdata/flume/source/dirregex/test/TestDirRegexSource.java
  AL    src/test/java/com/changhong/bigdata/flume/source/dirregex/test/TmpTest.java
 
 *****************************************************
 Printing headers for files without AL header...
 
 
 =======================================================================
 ==src/main/java/com/changhong/bigdata/flume/source/dirnginx/NginxSource.java
 =======================================================================
package com.changhong.bigdata.flume.source.dirnginx;

import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.FileOutputStream;
import java.io.IOException;
import java.util.ArrayList;
import java.util.List;
import java.util.Properties;
import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

import org.apache.commons.lang.StringUtils;
import org.apache.flume.ChannelException;
import org.apache.flume.Context;
import org.apache.flume.Event;
import org.apache.flume.EventDrivenSource;
import org.apache.flume.conf.Configurable;
import org.apache.flume.event.EventBuilder;
import org.apache.flume.instrumentation.SourceCounter;
import org.apache.flume.source.AbstractSource;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;


import com.google.common.base.Preconditions;
import com.google.gson.Gson;


/**
 * @ClassName:NginxSource
 * @Decription:ç›‘æŽ§ç›®å½•Nginx ç›®å½•ï¼ŒæŒ‰å­—èŠ‚æ•°æ ¸å¯¹é‡å¯ç»­è¯?.æ–­ç‚¹ç»­ä¼ ï¼Œæ­£åˆ™åŒ¹é…å†…å®¹æå–æ•°æ®ï¼Œæ­£åˆ™åŒ¹é…æ–‡ä»¶åï¼Œå†…å­˜ä½¿ç”¨ä¸Šé™tolalMemoryå¤§äºŽ
 * maxMemoryçš?0.4
 * @author Niuwenchen
 * @date 2016-10-26 15:00:00
 * */

public class NginxSource extends AbstractSource implements EventDrivenSource, Configurable{

	private Logger logger= LoggerFactory.getLogger(NginxSource.class);
	private File monitorDir,checkFile; 									// ç›‘æŽ§ç›®å½•
	private Pattern monitorFilePattern, contentPattern;                 // æ–‡ä»¶å?  æ–‡ä»¶å†…å®¹
//	private long delayTime;
	private String charsetName;
	private int batchSize;
	private ScheduledExecutorService executor;

 =======================================================================
 ==src/main/java/com/jackniu/SpoolSource.java
 =======================================================================
package com.jackniu;

import java.io.File;
import java.io.FileFilter;
import java.util.List;
import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;

import org.apache.flume.Context;
import org.apache.flume.CounterGroup;
import org.apache.flume.Event;
import org.apache.flume.client.avro.ReliableSpoolingFileEventReader;
import org.apache.flume.conf.Configurable;
import org.apache.flume.instrumentation.SourceCounter;
import org.apache.flume.source.AbstractSource;
import org.apache.flume.source.SpoolDirectorySource;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.common.base.Preconditions;

public class SpoolSource extends SpoolDirectorySource implements Configurable {
	 private static Logger logger = LoggerFactory.getLogger(SpoolSource.class);
	private String spoolDirectory;
	private String completedSuffix; // æ–‡ä»¶è¯»å–å®Œæ¯•çš„åŽç¼?
//	private String fileHeader; // æ˜¯å¦åœ¨eventçš„HEaderä¸­æ·»åŠ æ–‡ä»¶å
//	private String fileHeaderKey;  // è¿™æ˜¯eventçš„Headerä¸­çš„keyï¼Œvalueæ—¶æ–‡ä»¶å
	private int batchSize;     //ä¸?æ¬¡å¤„ç†çš„è®°å½•æ•°ç›®  é»˜è®¤ä¸?100
	
//	private String inputCharset; // ç¼–ç æ–¹å¼ï¼Œé»˜è®¤æ—¶UTF-8
//	private String ignorePattern;  // å¿½ç•¥å¤åˆç‰©æ¡ä»¶çš„æ–‡ä»¶å?
//	private String trackerDirPath;  // è¢«å¤„ç†æ–‡ä»¶å…ƒæ•°æ®çš„å­˜å‚¨ç›®å½•ï¼Œé»˜è®¤æ—?.flumespool

 	private CounterGroup counterGroup;
 	private ReliableSpoolingFileEventReader reader;
	private SourceCounter sourceCount;
 	
	@Override
	public synchronized void configure(Context context) {
		logger.info("**************Configure********************");
		spoolDirectory=context.getString("spoolDir");
		Preconditions.checkState(spoolDirectory!=null,
				"Configuration must specity a apooling directory");
		completedSuffix=context.getString("completedSuffix",".COMPLETED");
		batchSize=context.getInteger("batchSize",100);
		logger.info("***"+spoolDirectory+"  *****"+completedSuffix+"********"+batchSize);
		sourceCount = getSourceCounter();
		
	}

 =======================================================================
 ==src/main/java/com/jackniu/Test.java
 =======================================================================
package com.jackniu;

import com.google.gson.Gson;


public class Test {
	public static void main(String[] args)
	{
		Json json = new Json();
		json.fileName = "/opt/flume";
		json.logBody ="ip";
		json.ip = "0.0.0.0";                                  // ä½†æ˜¯è¿™é‡Œçš„IPè¿˜æ˜¯æœ‰ç‚¹é—®é¢˜
		Gson gson = new Gson();
		String eventString = gson.toJson(json);
		System.out.println(eventString.toString());
	}
	
}
class Json{
	String fileName;    // ä¸šåŠ¡åç§°
	String logBody ;    // æ—¥å¿—ä½?
	String ip;
}

 =======================================================================
 ==src/main/java/com/jackniu/TestEventSource.java
 =======================================================================
package com.jackniu;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.FileOutputStream;
import java.io.FileReader;
import java.io.IOException;
import java.util.ArrayList;
import java.util.List;
import java.util.Properties;
import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;

import org.apache.commons.lang.StringUtils;
import org.apache.flume.ChannelException;
import org.apache.flume.Context;
import org.apache.flume.Event;
import org.apache.flume.EventDrivenSource;
import org.apache.flume.conf.Configurable;
import org.apache.flume.event.EventBuilder;
import org.apache.flume.instrumentation.SourceCounter;
import org.apache.flume.source.AbstractSource;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.common.base.Preconditions;

public class TestEventSource extends AbstractSource implements EventDrivenSource, Configurable {
	private Logger logger= LoggerFactory.getLogger(TestEventSource.class);
	private File monitorDir,checkFile; // ç›‘æŽ§ç›®å½•
	private int batchSize;
	private ScheduledExecutorService executor;
	private SourceCounter sourceCounter;
	private int anchor=0;
	private Properties properties;
	private Properties tmpProperties = new Properties();
	
	
	@Override
	public void configure(Context context) {
		logger.info("----------------------TestEventSource configure...");
		String strMonitorDir = context.getString("monitorDir");
		Preconditions.checkArgument(StringUtils.isNotBlank(strMonitorDir), "Missing Param:'monitorDir'");
		batchSize = context.getInteger("batchSize");
		Preconditions.checkArgument(batchSize > 0, "'batchSize' must be greater than 0");
		
		String strCheckFile = context.getString("checkFile");
